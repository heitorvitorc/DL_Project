{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('projeto')",
   "display_name": "Python 3.8.5 64-bit ('projeto')",
   "metadata": {
    "interpreter": {
     "hash": "53317835051b77472428fe4e8e408a900643a93a2d2a4e5a5bdd10a8f1b52561"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Porous media flow field estimation using cGANs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Import libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn # All neural network modules, e.g. nn.Linear, nn.Conv2d, BatchNorm, Loss Functions\n",
    "import torch.optim as optim # For all Optmization algorithms, SGD, Adam, etc\n",
    "import torchvision.datasets as datasets # Has standard datasets we can import in a nice way\n",
    "import torchvision.transforms as transforms # Transformations we can perform on our dataset\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset, DataLoader # Gives easier dataset management and creates mini batches\n",
    "# from torch.utils.tensorboard import SummaryWriter # to print to tensorboard\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "### Define data paths"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total samples: 200\nTrain samples 170\nTest samples 30\n"
     ]
    }
   ],
   "source": [
    "# Get mesh and velocity data paths\n",
    "mesh_paths = glob.glob('./mesh_data/*.tif')\n",
    "vel_paths = glob.glob('./vel_data/*.tif')\n",
    "\n",
    "total_samples = len(mesh_paths)\n",
    "train_size = 0.85\n",
    "\n",
    "# Separate training samples\n",
    "train_mesh_paths = mesh_paths[:int(total_samples*train_size)]\n",
    "train_vel_paths = vel_paths[:int(total_samples*train_size)]\n",
    "\n",
    "# Separate test samples\n",
    "test_mesh_paths = mesh_paths[int(total_samples*train_size):]\n",
    "test_vel_paths = vel_paths[int(total_samples*train_size):]\n",
    "\n",
    "print(\"Total samples:\", total_samples)\n",
    "print(\"Train samples\", len(train_mesh_paths))\n",
    "print(\"Test samples\", len(test_mesh_paths))"
   ]
  },
  {
   "source": [
    "### Preprocess the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset class to consider an image pair \n",
    "class mesh_vel_dataset(Dataset):\n",
    "    def __init__(self, meshes, veles, train=True):\n",
    "        self.meshes = meshes\n",
    "        self.vels = veles\n",
    "    \n",
    "    def transform(self, mesh, vel):\n",
    "        resize_mesh = transforms.Resize(size = (64,64), interpolation=Image.NEAREST)\n",
    "        resize_vel = transforms.Resize(size = (64,64), interpolation=Image.NEAREST)\n",
    "        gray =  transforms.Grayscale(num_output_channels=1)\n",
    "\n",
    "        mesh = TF.to_tensor(resize_mesh(mesh))\n",
    "        vel = TF.to_tensor(resize_vel(vel))\n",
    "\n",
    "        vel = vel.__ge__(0.7).type(torch.FloatTensor)\n",
    "        \n",
    "        return mesh, vel\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        mesh = Image.open(self.meshes[idx])\n",
    "        vel = Image.open(self.vels[idx])\n",
    "        x, y = self.transform(mesh, vel)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.meshes)\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Load the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "170\n"
     ]
    }
   ],
   "source": [
    "train_data = mesh_vel_dataset(train_mesh_paths, train_vel_paths, train=True)\n",
    "train_loader = DataLoader(train_data, batch_size = 5, shuffle = True)\n",
    "\n",
    "test_data = mesh_vel_dataset(test_mesh_paths, test_vel_paths, train=False)\n",
    "test_loader = DataLoader(test_data, batch_size = 5, shuffle = False)\n",
    "\n",
    "print(len(train_loader.dataset))"
   ]
  },
  {
   "source": [
    "### Build the Discriminator"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "class Discriminator(torch.nn.Module):\n",
    "    \n",
    "    #3 hidden-layer discriminative nn\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        input_dim = 256+256\n",
    "        output_dim = 1\n",
    "        self.label_embedding = nn.Embedding(10,10)\n",
    "        \n",
    "        self.hidden0=nn.Sequential(\n",
    "            nn.Conv2d(1,64,kernel_size=2, stride=2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.hidden1=nn.Sequential(\n",
    "            nn.Conv2d(64,128,kernel_size=2, stride=2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.hidden2=nn.Sequential(\n",
    "            nn.Conv2d(128,256,kernel_size=2, stride=2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.out=nn.Sequential(\n",
    "            nn.Conv2d(256,1,kernel_size=2, stride=2),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x,msk):\n",
    "        x = torch.cat([x,msk])\n",
    "\n",
    "        output = self.hidden0(x)\n",
    "        output = self.hidden1(output)\n",
    "        output = self.hidden2(output)\n",
    "        output = self.out(output)\n",
    "        return output"
   ]
  },
  {
   "source": [
    "### Build the Generator\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):#, channels_noise, channels_img, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size =2, stride =2)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            \n",
    "            nn.ConvTranspose2d(1, 64, kernel_size=4, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "source": [
    "### Build the Adversarial Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class adversarialModel(object):\n",
    "    def __init__(self, num_epochs=500, samples=3, batch=5, betas=(0.5,0.5), g_lr = 0.001, d_lr = 0.001,                      size = 64, data_path = './models', channels_img = 1, channels_noise =  64, features_g = 16,                 features_d = 16, dataloader = train_loader, transforms = None):\n",
    "        \n",
    "        # Define parameters\n",
    "        self.num_epochs = num_epochs\n",
    "        self.samples = samples\n",
    "        self.batch = batch\n",
    "        self.betas = betas\n",
    "        self.g_lr = g_lr\n",
    "        self.d_lr = d_lr\n",
    "        self.size = size\n",
    "        self.channels_img = channels_img\n",
    "        self.channels_noise = channels_noise\n",
    "        self.features_d = features_d\n",
    "        self.features_g = features_g\n",
    "        self.dataset = 'input_data'\n",
    "        self.name = 'adversarialModel'\n",
    "        self.output_dir = glob.glob('./')\n",
    "\n",
    "        # Generator and Discriminator\n",
    "        self.generator = Generator()\n",
    "        self.discriminator = Discriminator()\n",
    "\n",
    "        # Optimizers\n",
    "        self.optim_g = optim.Adam(self.generator.parameters(), lr = self.g_lr, betas =(0.9, 0.999))\n",
    "        self.optim_d = optim.Adam(self.discriminator.parameters(), lr = self.d_lr, betas =(0.9, 0.999))\n",
    "\n",
    "        decay_factor = 0.5 \n",
    "\n",
    "        # Loss functions\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "        self.L1_loss = nn.L1Loss()\n",
    "\n",
    "        # Dataset\n",
    "        self.dataloader = dataloader\n",
    "\n",
    "    def train(self):\n",
    "        losses_d = []\n",
    "        losses_g = []\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            for batch_idx, (meshes, vels) in enumerate(self.dataloader):\n",
    "\n",
    "                meshes = meshes.to(device)\n",
    "                vels = vels.to(device)\n",
    "\n",
    "                # Discriminator loss\n",
    "                self.optim_d.zero_grad()\n",
    "\n",
    "                fake_vels = self.generator(meshes)\n",
    "                pred_real = self.discriminator(meshes, vels)\n",
    "                ones = torch.ones(pred_real.shape).to(device)\n",
    "\n",
    "                pred_fake = self.discriminator(meshes, fake_vels)\n",
    "                zeros = torch.zeros(pred_fake.shape).to(device)\n",
    "\n",
    "                loss_discriminator_real = self.bce_loss(pred_real, ones)\n",
    "                loss_discriminator_fake = self.bce_loss(pred_fake, zeros)\n",
    "                loss_discriminator = loss_discriminator_real + loss_discriminator_fake\n",
    "                losses_d.append(loss_discriminator)\n",
    "\n",
    "                loss_discriminator.backward()\n",
    "                self.optim_d.step()\n",
    "\n",
    "                # Generator Loss\n",
    "                self.optim_g.zero_grad()\n",
    "\n",
    "                fake_vels = self.generator(meshes)\n",
    "                loss_generator_bce = self.bce_loss(self.discriminator(meshes, fake_vels), ones)\n",
    "                loss_generator_l1 = self.L1_loss(fake_vels, vels)\n",
    "                loss_generator = loss_generator_bce + loss_generator_l1\n",
    "                losses_g.append(loss_generator)\n",
    "\n",
    "                loss_generator.backward()\n",
    "                self.optim_g.step()\n",
    "\n",
    "                if(epoch%10 == 0  and batch_idx==0):\n",
    "                    print('Epoch : ', epoch)\n",
    "                    print(\"generator loss: \",loss_generator)\n",
    "                    print(\"discriminator loss: \",loss_discriminator)\n",
    "\n",
    "                if(epoch%50 ==0 and batch_idx==0):\n",
    "                    plt.title(\"Model losses\")\n",
    "                    plt.plot(losses_d, label=\"Discriminator\")\n",
    "                    plt.plot(losses_g, label=\"Generator\")\n",
    "                    plt.xticks(np.arange(1, epoch+1, 1.0))\n",
    "                    plt.legend()\n",
    "                    plt.show()\n",
    "    \n",
    "\n",
    "    def evaluate(self, test_loader = test_loader):\n",
    "        losses_d = []\n",
    "        losses_g = []\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (meshes, vels) in enumerate(test_loader):\n",
    "\n",
    "                meshes = meshes.to(device)\n",
    "                vels = vels.to(device)\n",
    "\n",
    "                fake_vels = self.generator(meshes)\n",
    "                pred_real = self.discriminator(meshes, vels)\n",
    "                ones = torch.ones(pred_real.shape).to(device)\n",
    "\n",
    "                pred_fake = self.discriminator(meshes, fake_vels)\n",
    "                zeros = torch.zeros(pred_fake.shape).to(device)\n",
    "\n",
    "                loss_dicriminator_real = self.bce_loss(pred_real, ones)\n",
    "                loss_dicriminator_fake = self.bce_loss(pred_fake, zeros)\n",
    "                loss_discriminator = loss_dicriminator_real + loss_dicriminator_fake\n",
    "\n",
    "                fake_vels = self.generator(meshes)\n",
    "                loss_generator_bce = self.bce_loss(self.discriminator(meshes, fake_vels), ones)\n",
    "                loss_generator_l1 = self.L1_loss(fake_vels, vels)\n",
    "                loss_generator = loss_generator_bce + loss_generator_l1\n",
    "                loss_generator = loss_generator_bce + loss_generator_l1\n",
    "\n",
    "                losses_d.append(loss_discriminator)\n",
    "                losses_g.append(loss_generator)\n",
    "\n",
    "                if(batch_idx==0):\n",
    "                    print(\"generator loss: \",loss_generator)\n",
    "                    print(\"discriminator loss: \",loss_discriminator)\n",
    "                    plt.title(\"Model losses\")\n",
    "                    plt.plot(losses_d, label=\"Discriminator\")\n",
    "                    plt.plot(losses_g, label=\"Generator\")\n",
    "                    \n",
    "                    plt.legend()\n",
    "                    \n",
    "                    fig = plt.figure()\n",
    "                    ax1 = fig.add_subplot(2,2,1)\n",
    "                    ax1.imshow(np.squeeze(masks[0].cpu().detach().numpy()),cmap = 'gray')\n",
    "                    ax2 = fig.add_subplot(2,2,2)\n",
    "                    ax2.imshow(np.squeeze(fake_images[0].cpu().detach().numpy()),cmap = 'gray')    \n",
    "                    ax3 = fig.add_subplot(2,2,3)\n",
    "                    ax3.imshow(np.squeeze(images[0].cpu().detach().numpy()),cmap = 'gray')\n",
    "        \n",
    "                    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Set the hyperparameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = adversarialModel(num_epochs=800, dataloader = train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_loader))"
   ]
  },
  {
   "source": [
    "### Instantiate Discriminator and Generator"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}